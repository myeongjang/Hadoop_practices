1.centos7을 버추얼 박스에 설치한다
2. 여러가지 설정을 변경해야 하는데
   - 네트워크에서 NAT





전에 수정 했던 
vi /etc/hosts 에서 지웠던 내용을 다시 채워야 한다

127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4 
::1         localhost localhost.localdomain localhost6 localhost6.localdomain
192.168.103.XXX nn1

vi /etc/sysconfig/network 에서
전부다 주석처리 한다

hduser로 바꾸고 경로 지정과 소스와 java 버전을 확인한다
[root@nn1 ~]# su - hduser
마지막 로그인: 수 11월 14 12:44:48 KST 2018 일시 pts/0
[hduser@nn1 ~]$ vi ~/.bash_profile
경로 수정
vi ~/.bash_profile
export JAVA_HOME=/home/hduser/jdk1.8.0_191
export HADOOP_HOME=/home/hduser/hadoop
export YARN_HOME=${HADOOP_HOME}
export HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_HOME}/lib/native
export HADOOP_OPTS=-Djava.net.preferIPv4Stack=true
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
PATH=$JAVA_HOME/bin:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:$PATH
export PATH

[hduser@nn1 ~]$ source ~/.bash_profile
[hduser@nn1 ~]$ java -version
java version "1.8.0_191"
Java(TM) SE Runtime Environment (build 1.8.0_191-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)
[hduser@nn1 ~]$ echo $HADOOP_CONF_DIR
/home/hduser/hadoop/etc/hadoop

루트로 관리자를 바꾸고 hadoop 연계 폴더와 그안에 데이터 노드&네임노드를 만든다 (opt에서)
[hduser@nn1 opt]$ su - root
cd /opt/

mkdir -p dfs/namenode
mkdir -p dfs/datanode
---------------------------------------------------

디렉토리 내부를 깔끔하게 한다
ls
rm -fr rh
그리고 su - hduser로 바꾼다!!!
cd $HADOOP_CONF_DIR
---------------------------------------
하둡 설정을 바꾼다
vi hadoop-env.sh
그리고 그 상태 그대로에서 /JAVA_H 를 입력하고 엔터를 누른다. 그럼 찾기 기능이 실현된다
export JAVA_HOME=/home/hduser/jdk1.8.0_191 <-- 추가한다
/LOG를 검색하고 
export HADOOP_LOG_DIR=/home/hduser/hadoop/logs <--추가한다



------------------------------------------------------------------------------------------------
vi core-site.xml

<configuration>
<property>
        <name>fs.default.name</name>
        <value>hdfs://master:9000</value>
</property>
<property>
        <name>dfs.permissions</name>
        <value>false</value>
</property>
</configuration>
------------------------------------------------------------------------------------------------

vi hdfs-site.xml

<configuration>
<property>
        <name>dfs.data.dir</name>
        <value>/opt/dfs/datanode</value>
</property>
<property>
         <name>dfs.namenode.name.dir</name>
        <value>/opt/dfs/namenode</value>

</property>
<property>
        <name>dfs.replication</name>
        <value>1</value>

</property>

</configuration> 
---------------------------------------------------------------------------------------

vi yarn-site.xml
<configuration>

<!-- Site specific YARN configuration properties -->
<property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>

</property>
<property>
        <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>

</property>
<property>
        <name>yarn.resourcemanager.address</name>
        <value>master:8032</value>

</property>
<property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>master:8088</value>

</property>
<property>
        <name>yarn.resourcemanager.resource-tracker.address</name>
        <value>master:8031</value>

</property>

</configuration>

-------------------------------------------------------------------------------
cp mapred-site.xml.template mapred-site.xml
-----------------------------------------------------------------------------

 vi mapred-site.xml

<configuration>
<property>
        <name>mapreduce.jobtracker.address</name>
        <value>nn1:54311</value>

</property>
<property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>

</property>
</configuration>
